# 深層学習 day３ Section７：Ａｔｔｅｎｔｉｏｎ　Ｍｅｃｈａｎｉｓｍ

## 確認テスト１

ＲＮＮとｗｏｒｄ２ｖｅｃ、ｓｅｑ２ｓｅｑとＡｔｔｅｎｔｉｏｎの違いを簡潔に述べよ。

解答：

ＬＳＴＭは入力ゲート、出力ゲート、忘却ゲートそしてＣＥＣ、それぞれ４つの部品を持つ事で構成されていた。  
そのため、ＬＳＴＭではパラメータ数が多く、計算負荷が高くなるという課題があった。  
その中にあるＣＥＣであるが、問題点としては学習能力が無い事が挙げられる。（そのために３つのゲートを周りに付け、学習機能を持たせている、というのがＣＥＣの根本的な動きになっている。）  

   

## 確認テスト２

ＬＳＴＭとＧＲＵの違いを簡潔に述べよ。

解答：

- ＬＳＴＭには入力ゲート、出力ゲート、忘却ゲートの３つのゲートとＣＥＣがある。  
１方のＧＲＵにはＣＥＣが無く更新ゲートとリセットゲートを持つ。

- ＬＳＴＭはパラメータが多く、ＧＲＵはパラメータが少ない。

- 結果的にＬＳＴＭよりＧＲＵの方が計算量は少ない（重要）。


