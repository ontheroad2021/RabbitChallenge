# 深層学習 day１ Section３：出力層

## 確認テスト１

誤差関数（２乗和誤差、残差平方和）において、
* なぜ、引き算するのみではなく、二乗するのか述べよ
* 下式の1/2はどういう意味を持つか述べよ

解答：

* 全体でどれ位誤差があったかを知りたいとき、引き算したものの総和はゼロになる。
  各々を二乗したものを足し合わせる事によって、それを防ぐ事ができる。
* 誤差逆伝播の計算で、誤差関数を微分する必要があるのだが、その際に1/2があると係数が相殺される計算式が簡単になるため。
   

## 確認テスト２

①～③の数式該当するソースコードを示し、一行づつ処理の説明をせよ。

解答：
```    
# 出力層の活性化関数
# ソフトマックス関数
def softmax(x):
    if x.ndim == 2:
        x = x.T
        x = x - np.max(x, axis=0)
        y = np.exp(x) / np.sum(np.exp(x), axis=0)
        return y.T

    x = x - np.max(x) # オーバーフロー対策
    return np.exp(x) / np.sum(np.exp(x))
```
