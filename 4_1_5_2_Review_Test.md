# 深層学習 day３ Section５：Ｓｅｑ２ｓｅｑ

## 確認テスト１

下記の選択肢から、ｓｅｑ２ｓｅｑについて説明しているものを選べ。  
（1）時刻に関して順方向と逆方向のRNNを構成し、それら2つの中間層表現を特徴量として利用するものである。  
（2）RNNを用いたEncoder-Decoderモデルの一種であり、機械翻訳などのモデルに使われる。  
（3）構文木などの木構造に対して、隣接単語から表現ベクトル（フレーズ）を作るという演算を再帰的に行い（重みは共通）、文全体の表現ベクトルを得るニューラルネットワークである。  
（4）RNNの一種であり、単純なRNNにおいて問題となる勾配消失問題をCECとゲートの概念を導入することで解決したものである。  


解答：

ＬＳＴＭは入力ゲート、出力ゲート、忘却ゲートそしてＣＥＣ、それぞれ４つの部品を持つ事で構成されていた。  
そのため、ＬＳＴＭではパラメータ数が多く、計算負荷が高くなるという課題があった。  
その中にあるＣＥＣであるが、問題点としては学習能力が無い事が挙げられる。（そのために３つのゲートを周りに付け、学習機能を持たせている、というのがＣＥＣの根本的な動きになっている。）  

   

## 確認テスト２

ＬＳＴＭとＧＲＵの違いを簡潔に述べよ。

解答：

- ＬＳＴＭには入力ゲート、出力ゲート、忘却ゲートの３つのゲートとＣＥＣがある。  
１方のＧＲＵにはＣＥＣが無く更新ゲートとリセットゲートを持つ。

- ＬＳＴＭはパラメータが多く、ＧＲＵはパラメータが少ない。

- 結果的にＬＳＴＭよりＧＲＵの方が計算量は少ない（重要）。


