<!DOCTYPE html>
<html>
<head>

<meta name="twitter:title" content="深層学習後半レポート"/>
<meta name="twitter:description" content="深層学習後半の要点のまとめと実装演習結果へのリンクです。"/>
<meta name="twitter:image" content="https://ontheroad2021.github.io/RabbitChallenge/images/RabbitChallengeImage.png"/>
<meta name="twitter:card" content="summary"/>

<style>
body {
	background-color: white;
}
table {
	border-collapse: collapse;
	background-color: lightgray;
}
th, td {
	border: 1px solid #333;
}
td {
	text-align: center;
}

.group { 
	background: powderblue;
	width: 100%;	
}

/*
.group:hover {
    background-color: lightsteelblue;
}
*/

.g1 { width:  5% }
.g2 { width: 10%; text-align: left; }
.g3 { width: 15%; text-align: left; }
.g4 { width: 25%; text-align: left; }
.g5 { width: 10%; text-align: }
.g6 { width: 10%; text-align: }
.g7 { width: 10%; text-align: }

.header {
	padding: 10px;
	text-align: center;
	background:steelblue;
	color: black;
	font-size: 20px;
	border: 1px solid #333;

	overflow-y: auto; 
    position: sticky; 
	top: 0; 
}
.left { display: table-cell; text-align: left; }
.right { display: table-cell; text-align: right; }

#navbar {
  padding: 0px;
  text-align: center;
  background-color: steelblue;
  color: black;
  font-size: 20px;
  /* border: 1px solid #333; */

  position: sticky; /* Make it stick/fixed */
  top: 0; /* Stay on top */
  transition: top 1.0s; /* Transition effect when sliding down (and up) */
}

</style>
</head>

<body>
	<div id="navbar">
		<table class="header">
			<tr>
				<th colspan="8"><h2>深層学習後半レポート</h2></th>
			</tr>
			<tr>
				<th width="5%">ビデオ視聴学習者提出区分け</th>
				<th width="10%">科目</th>
				<th width="15%">章タイトル</th>
				<th width="25%" class="left">１点１００文字以上で要点のまとめ</th>
				<th width="10%" class="left">実装演習結果キャプチャーまたはサマリーと考察</th>
				<th width="10%" class="left">「確認テスト」など、自身の考察結果</th>
				<th width="10%" class="left">演習問題や参考図書、修了課題など関連記事レポートによる加点</th>
			</tr>
		</table	>
	</div>
		
	<table class="group">
		<tr>
			<td class="g1" rowspan="13">【d】</td>
			<td class="g2" rowspan="7" class="left">深層学習day３</td>
			<td class="g3">
				Section１：再帰型ニューラルネットワークの概念
			</td>
			<td class="g4">
				<ul>
					
<li>ＲＮＮ（Ｒｅｃｃｕｒｅｎｔ　Ｎｅｕｒａｌ　Ｎｅｔｏｗｒｋ)</li>

<li>時系列データ（音声データ、株価データ、テキストデータ）に対応可能なニューラルネットワーク</li>
					
<li>ＲＮＮの数学的記述</li>
					
<li>ＲＮＮの特徴（再帰的構造）</li>
					
<li>ＢＰＴＴ（Ｂａｃｋ　Ｐｒｏｐａｇａｔｉｏｎ　Ｔｈｒｏｕｇｈ　Ｔｉｍｅ）とは：ＲＮＮにおいてのパラメータ調整方法の一種</li>
					
<li>ＢＰＴＴの数学的記述</li>
					
<li>ｔ時間目とｔ－１時間目には関係がある事が見てとれる。</li>
					
<li>パラメータの更新式</li>
					
<li>ＲＮＮが過去の時間を再帰的にたくわえている事を示している。</li>

				</ul>
			</td>
			<td class="g5">
				<a href="https://nbviewer.jupyter.org/github/ontheroad2021/RabbitChallenge/blob/main/4_1_1_1_3_1_simple_RNN.ipynb" target="_blank">ＲＮＮ</a><br>
			</td>
			<td class="g6">
				<a href="https://github.com/ontheroad2021/RabbitChallenge/blob/main/4_1_1_2_Review_Test.md" target="_blank">確認テスト（ＲＮＮ）</a>
			</td>
			<td class="g7">
				該当なし
			</td>
		</tr>
		<tr>
			<td class="left">
				Section２：ＬＳＴＭ
			</td>
			<td class="left">
				<ul>
<li>ＲＮＮの課題の解決：これまでに触れた勾配消失の解決方法（ｔａｎｈ等の勾配消失問題に強い活性化関数を用いる、あるいは正則化を用いる等）とは別に、構造自体を変えて解決したものがＬＳＴＭ。</li>

<li>勾配消失問題：誤差逆伝播法が下位層に進んで行くに連れて、勾配がどんどん緩やかになっていく。そのため、勾配降下法による更新では、下位層のパラメータはほとんど変わらず、訓練は最適解に収束しなくなる。（例）シグモイド関数</li>
										
<li>勾配爆発：勾配が層を逆伝播するごとに指数関数的に大きくなっていく⇒勾配クリッピング</li>
										
<li>ＬＳＴＭの全体図
					
					<ul>
					
<li>ＣＥＣ（Ｃｏｎｓｔａｎｔ Ｅｒｒｏｒ Ｃａｒｏｕｓｅｌ）記憶機能だけを持つもの</li>
										
<li>ＣＥＣの課題：入力データについて、時間依存に関係なく一律である（ニューラルネットワークの学習特性が無いという事）</li>
					
<li>入力ゲートと出力ゲートを追加する事で、それぞれのゲートへの入力値の重みを、重み行列で可変とする（ＣＥＣの課題を解決）</li>
					
					</ul>
									
<li>ＬＳＴＭの現状</li>

					<ul>
						
<li>ＣＥＣには過去の情報が全て保管されている。</li>
										
<li>ＬＳＴＭブロックの課題：過去の情報が要らなくなった場合、そのタイミングで情報を忘却する機能が必要⇒忘却ゲート</li>
										
<li>覗き穴結合：ＣＥＣ自身の値に重み行列を介して伝播可能にした構造（実際にはあまり大きな効果の改善は見られない。）</li>
										
					</ul>
				</ul>
			</td>
			<td>
				<a href="https://nbviewer.jupyter.org/github/ontheroad2021/RabbitChallenge/blob/main/4_1_1_1_3_1_simple_RNN_after.ipynb" target="_blank">ＲＮＮ（アフター）</a>
			</td>
			<td>
				<a href="https://github.com/ontheroad2021/RabbitChallenge/blob/main/4_1_2_2_Review_Test.md" target="_blank">確認テスト（ＬＳＴＭ）</a>
			</td>
			<td>
				該当なし			
			</td>
		</tr>
		<tr>
			<td class="left">
				Section３：ＧＲＵ
			</td>
			<td class="left">
				<ul>

<li>ＧＲＵ（Ｇａｔｅｄ Ｒｅｃｕｒｒｅｎｔ Ｕｎｉｔ）</li>

<li>ＬＳＴＭの改良版：ＬＳＴＭでは、パラメータ数が多く、計算負荷が高くなる問題があった。</li>
					
<li>そのため、ＧＲＵはパラメータを大幅に削減し（計算負荷が低い）、精度は同等またはそれ以上が望める様になった構造を持つ。</li>

				</ul>
			</td>
			<td>
				<a href="https://nbviewer.jupyter.org/github/ontheroad2021/RabbitChallenge/blob/main/4_1_2_1_predict_word.ipynb" target="_blank">ＧＲＵ</a>
			</td>
			<td>
				<a href="https://github.com/ontheroad2021/RabbitChallenge/blob/main/4_1_3_2_Review_Test.md" target="_blank">確認テスト（ＧＲＵ）</a>
			</td>
			<td>
				該当なし			
			</td>
		</tr>
		<tr>
			<td class="left">
				Section４：双方向ＲＮＮ
			</td>
			<td class="left">
				<ul>

<li>双方向ＲＮＮ（Ｂｉｄｉｒｅｃｔｉｏｎａｌ ＲＮＮ）</li>

<li>過去の情報だけでなく、未来の情報を加味する事で、精度を向上させるためのモデル。例）文章の推敲や機械翻訳等</li>
					
<li>文章というのは過去の情報も未来の情報も１度に入ってくる。過去の単語の羅列に加えて、その先に書いてある単語の羅列についても自由にアクセスができる。</li>
					
				</ul>
			</td>
			<td>
				該当なし
			</td>
			<td>
				該当なし
			</td>
			<td>
				該当なし		
			</td>
		</tr>
		<tr>
			<td class="left">
				Section５：Ｓｅｑ２Ｓｅｑ
			</td>
			<td class="left">
				

「Ｓｅｑ２ｓｅｑ（Ｓｅｑｕｅｎｃｅ to Ｓｅｑｕｅｎｃｅ）」

				<ul>

<li>Ｓｅｑ２ｓｅｑとはＥｎｃｏｄｅｒ－Ｄｅｃｏｄｅｒモデルの１種を指します（時系列データを入力に取って時系列のデータを出力するモデル）。</li>
					
<li>Ｓｅｑ２ｓｅｑの具体的な用途とは機械対話や機械翻訳等に使用されています。</li>
					
<li>Ｅｎｃｏｄｅｒ ＲＮＮ：文の意味を集約する。文から文脈の意味ベクトルの抽出。</li>
					
					<ul>
					
<li>Ｔａｋｉｎｇ：文章を単語等のトークン事に分割し、トークン毎のＩＤに分割する（ＯＮＥ ＨＯＴ ＶＥＣＴＯＲ）。</li>
					
<li>Ｅｍｂｅｄｄｉｎｇ：ＩＤからそのトークンを表す分散表現ベクトルに変換。数字の並びが似かよっている事は似かよった意味を持つ単語という事になる ⇒ 単語の意味を抽出したベクトル。</li>
					
<li>Ｅｎｃｏｄｅｒ ＲＮＮ：ベクトルを順番にＲＮＮに入力していく。</li>
					
					</ul>
						
<li>Ｅｎｃｏｄｅｒ ＲＮＮ処理手順</li>
						
					<ul>
						
<li>最後のベクトルを入れた時のｈｉｄｄｅｎ ｓｔａｔｅをｆｉｎａｌ ｓｔａｔｅとして取っておく。</li>
					
<li>このｆｉｎａｌ ｓｔａｔｅがｔｈｏｕｇｈｔ ｖｅｃｔｏｒと呼ばれ、入力した文の意味を表すベクトルになる。</li>
					
<li>ＭＬＭ － Ｍａｓｋｅｄ Ｌａｎｇｕａｇｅ Ｍｏｄｅｌ（ＢＥＲＴ）</li>
						
					</ul>
					
<li>Ｄｅｃｏｄｅｒ ＲＮＮ：システムがアウトプットデータを単語等のトークン毎に生成する構造。</li>
					
<li>Ｄｅｃｏｄｅｒ ＲＮＮ 処理手順</li>
					
					<ul>
						
<li>Ｄｅｃｏｄｅｒ ＲＮＮ：Ｅｎｃｏｄｅｒ ＲＮＮのｆｉｎａｌ ｓｔａｔｅ（ｔｈｏｕｇｈｔ ｖｅｃｔｏｒ）から、各ｔｏｋｅｎの生成確率を出力していきます。ｆｉｎａｌ ｓｔａｔｅをＤｅｃｏｄｅｒ ＲＮＮのｉｎｉｔｉａｌ ｓｔａｔｅとして設定し、Ｅｍｂｅｄｄｉｎｇを入力。</li>
					
<li>Ｓａｍｐｌｉｎｇ：生成確率に基づいてｔｏｋｅｎをランダムに選びます。</li>
					
<li>Ｅｍｂｅｄｄｉｎｇ：２で選ばれたｔｏｋｅｎをＥｍｂｅｄｄｉｎｇしてＤｅｃｏｄｅｒ ＲＮＮへの次の入力とします。</li>
					
<li>Ｄｅｔｏｋｅｎｉｚｅ：１～３を繰り返し、２で得られたｔｏｋｅｎを文字列に直します。</li>	
						
					</ul>
				</ul>
						
「ＨＲＥＤ(Ｔｈｅ Ｈｉｅｒａｒｃｈｉｃａｌ Ｒｅｃｕｒｒｅｎｔ Ｅｎｃｏｄｅｒ－Ｄｅｃｏｄｅｒ)」
				<ul>	
<li>Ｓｅｑ２ｓｅｑの課題：１問１答しかできない（問に対して文脈も何もなく、ただ応答が行われ続ける。）</li>
					
<li>ＨＲＥＤ：文章の過去の文脈というものを何かしら取れるようにできないかという試み。Ｓｅｑ２ｓｅｑが単語に扱ったのに加えて、文脈自体（１文、１文も）同様に扱ってみたら良いのではないか。</li>
					
<li>ＨＲＥＤとは：Ｓｅｑ２ｓｅｑ＋ＣｏｎｔｅｘｔＲＮＮ</li>
					
<li>ＣｏｎｔｅｘｔＲＮＮ：Ｅｎｃｏｄｅｒのまとめた各文章の系列をまとめて、これまでの会話コンテクスト全体を表すベクトルに変換する構造。 ⇒ 過去の発話の履歴を加味した返答ができる。</li>
					
<li>ＨＲＥＤの課題：（しくみを複雑にすると何か問題が起こるというのがディープラーニングの特徴です。）ＨＲＥＤでは確かに文脈を意識した文を作る事ができるのだが、ありがちな答えしか出さなくなる。あまりバリエーションに富んだ対話をしなくなってしまいます。例）「うん」「そうだね」等。</li>
					
				</ul>

「ＶＨＲＥＤ（Ｌａｔｅｎｔ Ｖａｒｉａｂｌｅ Ｈｉｅｒａｒｃｈｉｃａｌ Ｒｅｃｕｒｒｅｎｔ Ｅｎｃｏｄｅｒ－Ｄｅｃｏｄｅｒ）」
				<ul>	
<li>ＨＲＥＤというＳｅｑ２ｓｅｑとＣｏｎｔｅｘｔＲＮＮを合体させた文脈を意識しながら文を生成するモデルにヴァリエーションを持たせられるように工夫をしてみようという仕組みになります。</li>
				</ul>				
「オートエンコーダ」
				<ul>
<li>教師なし学習の１つ。次元削減を行う。（Ｅｎｃｏｄｅｒ、潜在変数Ｚ、Ｄｅｃｏｄｅｒ）からなる。</li>
				</ul>

「ＶＡＥ（Ｖａｒｉａｔｉｏｎａｌ Ａｕｔｏｅｎｃｏｄｅｒ）」

				<ul>
<li>洗剤変数Ｚを正規化する（確率分布Ｚ～Ｎ（０，１））。より汎用性の高い特徴を掴む。</li>						
				</ul>
			</td>
			<td>
				該当なし
			</td>
			<td>
				<a href="https://github.com/ontheroad2021/RabbitChallenge/blob/main/4_1_5_2_Review_Test.md" target="_blank">確認テスト（Ｓｅｑ２Ｓｅｑ）</a>
			</td>
			<td>
				該当なし			
			</td>
			<tr>
				<td class="left">
					Section６：Ｗｏｒｄ２ｖｅｃ
				</td>
				<td class="left">
					<ul>
	
	
					</ul>
				</td>
				<td>
					該当なし
				</td>
				<td>
					該当なし
				</td>
				<td>
					該当なし			
				</td>
				<tr>
					<td class="left">
						Section７：Ａｔｔｅｎｔｉｏｎ　Ｍｅｃｈａｎｉｓｍ
					</td>
					<td class="left">
						<ul>
		

		
						</ul>
					</td>
					<td>
						該当なし
					</td>
					<td>
						該当なし
					</td>
					<td>
						該当なし			
					</td>
		</tr>
			<td rowspan="6" class="left">深層学習day４</td>
			<td class="left">
				Section１：強化学習
			</td>
			<td class="left">
				<ul>

				</ul>
			</td>
			<td>
				不要
			</td>
			<td>
				不要	
			</td>
			<td>
				不要
			</td>
		</tr>	
		<tr>
			<td class="left">
				Section２：ＡｌｐｈａＧｏ
			</td>
			<td class="left">
				<ul>

				</ul>
			</td>
			<td>
				不要
			</td>
			<td>
				不要	
			</td>
			<td>
				不要			
			</td>
		</tr>
		<tr>
			<td class="left">
				Section３：軽量化・高速化技術
			</td>
			<td class="left">
				<ul>



				</ul>		
			</td>
			<td>
				不要
			</td>
			<td>
				不要	
			</td>
			<td>
				不要			
			</td>
		</tr>
		<tr>
			<td class="left">
				Section４：応用モデル
			</td>
			<td class="left">
				<ul>

				</ul>
			</td>
			<td>
				不要
			</td>
			<td>
				不要	
			</td>
			<td>
				不要			
			</td>
		</tr>
		<tr>
			<td class="left">
				Section５：Ｔｒａｎｓｆｏｒｍｅｒ
			</td>
			<td class="left">
				<ul>

				</ul>					
			</td>
			<td>
				不要
			</td>
			<td>
				不要	
			</td>
			<td>
				不要			
			</td>
		</tr>
		<tr>
			<td class="left">
				Section６：物体検知・セグメンテーション
			</td>
			<td class="left">
				<ul>

				</ul>					
			</td>
			<td>
				不要
			</td>
			<td>
				不要	
			</td>
			<td>
				不要			
			</td>
		</tr>	
	</table>

	<script>
		/* When the user scrolls down, hide the navbar. When the user scrolls up, show the navbar */
		var prevScrollpos = window.pageYOffset;
		window.onscroll = function() {
		var currentScrollPos = window.pageYOffset;
		  if (prevScrollpos > currentScrollPos) {
			document.getElementById("navbar").style.top = "0";
		  } else {
			document.getElementById("navbar").style.top = "-250px";
		  }
		  prevScrollpos = currentScrollPos;
		}
	</script>

</body>
</html>
